# Python Web Scraper & Local Publisher

A modular Python automation project that scrapes content from a public website, structures the data, and publishes it as formatted blog-ready HTML files.

This project demonstrates a complete automation pipeline:
- Web scraping
- Data cleaning and formatting
- Content publishing
- Clean project structure and documentation

Built as a reusable foundation for content automation, blogging workflows, and future API-based publishing (e.g., Google Blogger).

---

## ğŸš€ Features

- Scrapes quotes, authors, and tags from a public, scrape-friendly website
- Stores raw scraped data in CSV format
- Converts scraped data into formatted blog post content
- Publishes each item as a standalone HTML file
- Modular architecture (scraper â†’ formatter â†’ publisher)
- Easy to extend to APIs (Blogger, WordPress, CMS, etc.)

---

## ğŸ—‚ Project Structure

Blogger_scrapper/
â”‚
â”œâ”€â”€ Scraper/
â”‚ â””â”€â”€ scraper_quotes.py # Main scraper script
â”‚
â”œâ”€â”€ formatter/
â”‚ â””â”€â”€ format_posts.py # Converts CSV data into blog-ready posts
â”‚
â”œâ”€â”€ publisher/
â”‚ â””â”€â”€ local_publisher.py # Saves posts as HTML files locally
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ quotes.csv # Scraped raw data (ignored in git)
â”‚
â”œâ”€â”€ output/
â”‚ â””â”€â”€ post_*.html # Generated blog posts (ignored in git)
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## ğŸ§  How It Works

1. **Scraping**
   - Uses `requests` + `BeautifulSoup`
   - Extracts quote text, author, tags, source URL, and timestamp
   - Saves results to a CSV file

2. **Formatting**
   - Reads CSV into Pandas
   - Converts each row into structured blog post content (HTML)

3. **Publishing**
   - Writes each post to an individual `.html` file
   - Ready for upload to Blogger, WordPress, or CMS platforms

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Install dependencies

pip install -r requirements.txt

2ï¸âƒ£ Run the scraper module

python -m Scraper.scraper_quotes

3ï¸âƒ£ Output

Scraped data saved to:


data/quotes.csv
Generated blog posts saved to:


output/post_1.html
output/post_2.html
...
ğŸ›  Technologies Used
Python 3

Requests

BeautifulSoup

Pandas

CSV / HTML output

Modular Python architecture

ğŸ”’ Notes on Ethics & Safety
Scrapes only a public, scrape-friendly website

No login, authentication, or rate-limit bypassing

Designed to follow ethical scraping practices

ğŸ”® Future Improvements
Publish directly to Google Blogger via API

Add scheduling (cron / task scheduler)

Add logging and error recovery

Support additional content sources

Dockerized deployment

ğŸ‘¨â€ğŸ’» Author
Shawn Brooks
Python Automation & Web Scraping Developer

GitHub: https://github.com/sbrooks25222

LinkedIn: https://www.linkedin.com/in/shawn-brooks-2b84818b

